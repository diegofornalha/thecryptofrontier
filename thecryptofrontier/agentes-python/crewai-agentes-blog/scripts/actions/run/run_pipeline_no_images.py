#!/usr/bin/env python3
"""
Pipeline sem geraÃ§Ã£o de imagens - apenas RSS, traduÃ§Ã£o, formataÃ§Ã£o e publicaÃ§Ã£o
"""

import os
import sys
import json
import logging
import argparse
from pathlib import Path
from datetime import datetime

# Adicionar diretÃ³rio atual ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importar o crew sem imagens
from crew_no_images import get_crew

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(f"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
    ]
)
logger = logging.getLogger("pipeline")

def verify_environment():
    """Verifica apenas as variÃ¡veis essenciais (sem OpenAI)"""
    required_vars = {
        "GOOGLE_API_KEY": "Para traduÃ§Ã£o com Gemini",
        "STRAPI_PROJECT_ID": "Para publicaÃ§Ã£o no Strapi",
        "strapi_API_TOKEN": "Para autenticaÃ§Ã£o no Strapi"
    }
    
    missing_vars = []
    for var, description in required_vars.items():
        if not os.environ.get(var):
            missing_vars.append(f"{var} - {description}")
    
    if missing_vars:
        logger.warning("Algumas variÃ¡veis nÃ£o estÃ£o configuradas:")
        for var in missing_vars:
            logger.warning(f"  âš ï¸  {var}")
        # Continuar mesmo assim
    
    logger.info("âœ… Continuando sem geraÃ§Ã£o de imagens...")
    return True

def run_pipeline(limit: int = 3, clean: bool = False):
    """Executa o pipeline sem geraÃ§Ã£o de imagens"""
    logger.info(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            PIPELINE SEM IMAGENS - BLOG CREW                  â•‘
â•‘                                                              â•‘
â•‘   ğŸ“° RSS â†’ ğŸŒ TraduÃ§Ã£o â†’ ğŸ“ FormataÃ§Ã£o â†’ ğŸ“¤ PublicaÃ§Ã£o       â•‘
â•‘                                                              â•‘
â•‘   Processando {limit} artigos...                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Verificar ambiente (mas nÃ£o falhar)
    verify_environment()
    
    try:
        # Limpar arquivos antigos se solicitado
        if clean:
            logger.info("ğŸ§¹ Limpando arquivos antigos...")
            clear_old_files()
        
        # Criar instÃ¢ncia do crew
        crew = get_crew()
        
        # Preparar inputs
        inputs = {
            "limit": limit,
            "skip_images": True,  # IMPORTANTE: Pular geraÃ§Ã£o de imagens
            "date": datetime.now().strftime("%Y-%m-%d")
        }
        
        # Executar o pipeline
        logger.info("ğŸš€ Iniciando execuÃ§Ã£o do pipeline...")
        start_time = datetime.now()
        
        result = crew.kickoff(inputs=inputs)
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        logger.info(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âœ… PIPELINE CONCLUÃDO!                     â•‘
â•‘                                                              â•‘
â•‘   Tempo de execuÃ§Ã£o: {duration}                              
â•‘                                                              â•‘
â•‘   Posts processados SEM imagens!                             â•‘
â•‘   Acesse o Strapi Studio para visualizar!                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ Erro durante execuÃ§Ã£o: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

def clear_old_files():
    """Limpa arquivos antigos"""
    directories = [
        "posts_para_traduzir",
        "posts_traduzidos", 
        "posts_formatados",
        "posts_publicados"
    ]
    
    for dir_name in directories:
        dir_path = Path(dir_name)
        if dir_path.exists():
            for file in dir_path.glob("*.json"):
                try:
                    file.unlink()
                    logger.debug(f"Removido: {file}")
                except Exception as e:
                    logger.warning(f"Erro ao remover {file}: {e}")

def main():
    parser = argparse.ArgumentParser(description="Pipeline Blog Crew SEM geraÃ§Ã£o de imagens")
    parser.add_argument("--limit", type=int, default=3, help="NÃºmero de artigos para processar")
    parser.add_argument("--clean", action="store_true", help="Limpar arquivos antigos antes de executar")
    
    args = parser.parse_args()
    
    try:
        run_pipeline(limit=args.limit, clean=args.clean)
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸  Pipeline interrompido pelo usuÃ¡rio")
    except Exception as e:
        logger.error(f"\nâŒ Erro fatal: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()